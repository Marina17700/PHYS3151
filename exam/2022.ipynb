{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multivariate Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)  \n",
    "Hypothesis:  $$ h_{\\theta}(x) = \\theta_0+\\theta_1 x_1 +...+\\theta_n x_n $$\n",
    "where $x$ are the input features and $\\theta$ are the parameters of the model.\n",
    "\n",
    "Cost function: $$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$\n",
    "where m is the number of training examples.\n",
    "\n",
    "Hessian Matrix: \n",
    "$$ H_f = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n}\\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where the (i,j)th element represents the second partial derivative of the function $f$ with respect to the ith and jth variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)  \n",
    "The three methods differ in their approach to choosing the search direction and step size.\n",
    "\n",
    "Gradient Descent method follows the direction of steepest descent as determined by the negative gradient of the function at each point. The step size is controlled by learning rate.\n",
    "\n",
    "Steepest Descent is a variant of gradient descent where the step size is chosen to be the one that minimizes the objective function along the search direction. \n",
    "\n",
    "Conjugate Gradient method follows a conjugate direction that is orthogonal to all previous search directions. It will converge within N steps for a problem with N variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Given \n",
    "$$A= \n",
    "\\begin{pmatrix}\n",
    "30 & 15 & 22\\\\\n",
    "15 & 26 & 12\\\\\n",
    "22 & 12 & 25\n",
    "\\end{pmatrix}, \\quad\n",
    "\\textbf{b}=\\begin{pmatrix}\n",
    "8\\\\2\\\\6\n",
    "\\end{pmatrix}, \\quad\n",
    "c=12. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.zeros((3, 1))\n",
    "A = np.array([[30, 15, 22], [15, 26, 12], [22, 12, 25]])\n",
    "b = np.array([[8], [2], [6]])\n",
    "c = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, A, b, c):\n",
    "    return 0.5*x.T.dot(A).dot(x) - b.T.dot(x) + c\n",
    "\n",
    "\n",
    "def conj_grad(A, x, eps):\n",
    "    steps = [(x[:, 0])]\n",
    "    r = b - A.dot(x)\n",
    "    p = r\n",
    "    res = [r]\n",
    "    conj = [p]\n",
    "    rsold = r.T.dot(r)\n",
    "    rs0 = rsold\n",
    "    while rsold > eps**2 * rs0:\n",
    "        # Update the steps\n",
    "        Ap = A.dot(p)\n",
    "        alpha = rsold / p.T.dot(Ap)\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        rsnew = r.T.dot(r)\n",
    "        p = r + (rsnew / rsold) * p\n",
    "        rsold = rsnew\n",
    "\n",
    "        # Save the steps\n",
    "        steps.append((x[:, 0]))\n",
    "        res.append(rsnew)\n",
    "        conj.append(p)\n",
    "    return x, steps, res, conj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local minimum occurs at [ 0.30136986 -0.10958904  0.02739726] with value 10.821917808219178.\n"
     ]
    }
   ],
   "source": [
    "eps = 0.01\n",
    "x, steps, res, conj = conj_grad(A, x0, eps)\n",
    "print('Local minimum occurs at {} with value {}.'.format( x[:, 0], f(x, A, b, c)[0, 0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'PHYS3151-Machine-Learning-in-Physics-2023'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LeoisWTT/PHYS3151-Machine-Learning-in-Physics-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "class LR:\n",
    "    def __init__(self, x, y):\n",
    "        # Generate X, theta, and y\n",
    "        self.X = np.c_[np.ones((len(x), 1)), x]\n",
    "        self.theta = np.zeros((self.X.shape[1], 1))\n",
    "        self.y = y\n",
    "\n",
    "    # Computes the gradient of the cost function at the point theta\n",
    "    def gradient(self):\n",
    "        m = self.X.shape[0]\n",
    "        sigmoid = 1 / (1 + np.exp(-np.dot(self.X, self.theta)))\n",
    "        return (1 / m) * np.dot(self.X.T, sigmoid-self.y)\n",
    "\n",
    "    # Performs gradient descent to learn theta\n",
    "    def fit(self, n_iter=1000):\n",
    "        alpha = 0.5\n",
    "        I = int(n_iter/3)\n",
    "        for i in range(n_iter):\n",
    "            # Reduce the learning rate by half every n_iter/3 iterations\n",
    "            if i % I == 0:\n",
    "                alpha /= 2\n",
    "            self.theta = self.theta-alpha*self.gradient()\n",
    "        return self.theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_cm  petal_width_cm  class\n",
       "0              5.1             0.2      1\n",
       "1              4.9             0.2      1\n",
       "2              4.7             0.2      1\n",
       "3              4.6             0.2      1\n",
       "4              5.0             0.2      1\n",
       "5              5.4             0.4      1\n",
       "6              4.6             0.3      1\n",
       "7              5.0             0.2      1\n",
       "8              4.4             0.2      1\n",
       "9              4.9             0.1      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./PHYS3151-Machine-Learning-in-Physics-2023/logistic-regression/iris-data.csv')\n",
    "df = df[['sepal_length_cm', 'petal_width_cm', 'class']]\n",
    "df = df.loc[df['class'].isin(['Iris-setosa', 'Iris-versicolor'])] \n",
    "df['class'] = np.where(df['class'] == 'Iris-setosa', 1, -1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Method\n",
    "class SVM:\n",
    "    def __init__(self, x, y):\n",
    "        # Generate X, theta, and y\n",
    "        self.X = np.c_[np.ones((len(x), 1)), x]\n",
    "        self.theta = np.zeros((self.X.shape[1], 1))\n",
    "        self.y = y\n",
    "\n",
    "    def check(self):\n",
    "        # Returns a matrix of 1s and 0s\n",
    "        fx = np.multiply(self.y, (self.X.dot(self.theta)))\n",
    "        check = np.less(fx, np.ones(fx.shape))\n",
    "        check = np.where(check == True, 1, 0)\n",
    "        return check\n",
    "\n",
    "    def fit(self, n_iter=1000):\n",
    "        m = float(self.y.shape[0])\n",
    "\n",
    "        alpha = 0.5\n",
    "        X, y = self.X, self.y\n",
    "        for i in range(n_iter):\n",
    "\n",
    "            I = int(n_iter/3)\n",
    "            # Reduce the learning rate by half every iterations/3 iterations\n",
    "            if i % I == 0:\n",
    "                alpha /= 2\n",
    "            self.theta = self.theta + alpha * \\\n",
    "                ((np.multiply(self.check(), y)).T.dot(X)).T\n",
    "            self.theta[1:] = self.theta[1:] - alpha*self.theta[1:]/m\n",
    "\n",
    "        return self.theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000  # number of iterations\n",
    "model2 = SVM(df[['sepal_length_cm', 'petal_width_cm']].to_numpy(), df['class'].to_numpy().reshape(100,1))\n",
    "w = model2.fit(n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4,7.5,0.1)\n",
    "y = -(w[1]/w[2])*x - w[0]/w[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "A = df.loc[df['class'] == 1]\n",
    "B = df.loc[df['class'] == -1]\n",
    "ax.scatter(A['sepal_length_cm'], A['petal_width_cm'], label='Iris-setosa', c='g')\n",
    "ax.scatter(B['sepal_length_cm'], B['petal_width_cm'], label='Iris-versicolor', c='violet')\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('SVM')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA and Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Compute the covariance matrix $\\Sigma$. Then perform singular value decomposition on $\\Sigma$ to get its eigenvalues and eigenvectors of $\\Sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros(x.shape)\n",
    "x_mean = np.mean(x, axis=0)\n",
    "x_std = np.std(x, axis=0, ddof=0)\n",
    "for i in range(100):\n",
    "    z[:, i] = (x_mean[i]-x[:, i])\n",
    "\n",
    "cov = np.cov(z, rowvar=False)\n",
    "U, sigma, VT = la.svd(cov) # sigma is eigenvalue, U is eigenvector\n",
    "\n",
    "print('The covariance matrix is: \\n{}\\n'.format(cov))\n",
    "print('The eigenvalues are: {}\\n'.format(sigma))\n",
    "print('The eigenvectors are: {}\\n'.format(U))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Project the data onto the first three components and group the reduced data to three clusters using the K-means \n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_system(U, dimension):\n",
    "    U_reduced = U[:, :dimension]\n",
    "    reduced_vec = np.dot(z, U_reduced)\n",
    "    var = np.sum(sigma[:dimension])/np.sum(sigma[:])\n",
    "    return reduced_vec, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducevec, vari = reduce_system(U, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "p = ax.scatter(reducevec[:, 0], reducevec[:, 1],\n",
    "               reducevec[:, 2], c=t, cmap=\"coolwarm\")\n",
    "\n",
    "ax.set_xlabel('pc1')\n",
    "ax.set_ylabel('pc2')\n",
    "ax.set_zlabel('pc3')\n",
    "cb = fig.colorbar(p, shrink=0.55)\n",
    "cb.set_label(label='$T$', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean(pc, K=3, jmax=10):\n",
    "    # step 1 - choose 3 clusters at random\n",
    "    # step 2 - select random point as centroids\n",
    "    a = random.sample(range(0, len(pc)-1), K)\n",
    "    Centroids = np.zeros((K, 3))\n",
    "    for i in range(K):\n",
    "        Centroids[i, 0] = pc[a[i]][0]\n",
    "        Centroids[i, 1] = pc[a[i]][1]\n",
    "        Centroids[i, 2] = pc[a[i]][2]\n",
    "    diff = 1\n",
    "    j = 0\n",
    "    Centroids = pd.DataFrame(Centroids)\n",
    "    Centroids.columns = ['pc1', 'pc2', 'pc3']\n",
    "    principalComponents = pd.DataFrame(pc)\n",
    "    principalComponents.columns = ['pc1', 'pc2', 'pc3']\n",
    "    while (diff != 0):\n",
    "        XD = principalComponents\n",
    "        i = 1\n",
    "    # step 3 - assign all the points to the closest cluster centroid\n",
    "        for index1, row_c in Centroids.iterrows():\n",
    "            ED = []\n",
    "            for index2, row_d in XD.iterrows():\n",
    "                d1 = (row_c[\"pc1\"] - row_d[\"pc1\"])**2\n",
    "                d2 = (row_c[\"pc2\"] - row_d[\"pc2\"])**2\n",
    "                d3 = (row_c[\"pc3\"] - row_d[\"pc3\"])**2\n",
    "                d = np.sqrt(d1+d2+d3)\n",
    "                ED.append(d)\n",
    "            principalComponents[i] = ED\n",
    "            i = i + 1\n",
    "\n",
    "        C = []\n",
    "        for index, row in principalComponents.iterrows():\n",
    "            min_dist = row[1]\n",
    "            pos = 1\n",
    "            for i in range(K):\n",
    "                if row[i+1] < min_dist:\n",
    "                    min_dist = row[i+1]\n",
    "                    pos = i + 1\n",
    "            C.append(pos)\n",
    "        principalComponents[\"Cluster\"] = C\n",
    "    # step 4 - recompute centroids of newly formed clusters\n",
    "        Centroids_new = principalComponents.groupby(\n",
    "            [\"Cluster\"]).mean()[[\"pc3\", \"pc2\", \"pc1\"]]\n",
    "    # step 5 - repeat 3 and 4\n",
    "        if j == 0:\n",
    "            diff = 1\n",
    "            j = j+1\n",
    "        elif j < jmax:\n",
    "            diff = ((Centroids_new['pc3'] - Centroids['pc3'])**2).sum() + ((Centroids_new['pc2'] -\n",
    "                                                                            Centroids['pc2'])**2).sum() + ((Centroids_new['pc1'] - Centroids['pc1'])**2).sum()\n",
    "        else:\n",
    "            diff = 0\n",
    "        Centroids = principalComponents.groupby([\"Cluster\"]).mean()[\n",
    "            [\"pc3\", \"pc2\", \"pc1\"]]\n",
    "    return principalComponents, Centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for k in range(K):\n",
    "    data = principalComponents[principalComponents[\"Cluster\"] == k+1]\n",
    "    ax.scatter(data[\"pc1\"], data[\"pc2\"], data[\"pc3\"], alpha=0.5)\n",
    "\n",
    "ax.scatter(Centroids[\"pc1\"], Centroids[\"pc2\"], Centroids[\"pc3\"], c='red')\n",
    "ax.set_xlabel('pc1')\n",
    "ax.set_ylabel('pc2')\n",
    "ax.set_zlabel('pc3')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Schematic plot of perceptron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Denote the input layer as first layer, the hidden layer as second layer, and the output layer as third layer. The number of nodes in each layer is 2, 5, 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3, 2], [5, 1]])\n",
    "y = np.array([[2, 1]])\n",
    "sizes = [2,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(sizes)\n",
    "biases = [np.ones((y, 1)) for y in sizes[1:]]\n",
    "weights = [np.ones((y, x)) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "\n",
    "activations = [x]  # list to store all the activations, layer by layer\n",
    "zs = []            # list to store all the z vectors, layer by layer\n",
    "\n",
    "a = x\n",
    "m = x.shape[1]\n",
    "\n",
    "# forward propogation\n",
    "for b, w in zip(biases, weights):\n",
    "    z = np.dot(w, a) + b\n",
    "    zs.append(z)\n",
    "    a = sigmoid(z)\n",
    "    activations.append(a)\n",
    "\n",
    "\n",
    "# backward propogation\n",
    "delta = (activations[-1]-y)*sigmoid_prime(zs[-1])\n",
    "nabla_b[-1] = np.sum(delta, axis=1, keepdims=True)\n",
    "nabla_w[-1] = np.dot(delta, activations[-2].T)\n",
    "for l in range(2, num_layers):\n",
    "    delta = np.dot(weights[-l+1].T, delta) * sigmoid_prime(zs[-l])\n",
    "    nabla_b[-l] = np.sum(delta, axis=1, keepdims=True)\n",
    "    nabla_w[-l] = np.dot(delta, activations[-l-1].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^1_{10} } = -4.3411e-07 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 1 1 } }= -1.1735e-06 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 1 2 } }= -1.6551e-06 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^1_{20} } = -4.3411e-07 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 2 1 } }= -1.1735e-06 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 2 2 } }= -1.6551e-06 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^1_{30} } = -4.3411e-07 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 3 1 } }= -1.1735e-06 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 3 2 } }= -1.6551e-06 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^1_{40} } = -4.3411e-07 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 4 1 } }= -1.1735e-06 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 4 2 } }= -1.6551e-06 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^1_{50} } = -4.3411e-07 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 5 1 } }= -1.1735e-06 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 1 }_{ 5 2 } }= -1.6551e-06 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$\\frac{\\partial J}{\\partial \\Theta^2_{10} } = -0.0024814 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 2 }_{ 1 1 } }= -0.002481 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 2 }_{ 1 2 } }= -0.002481 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 2 }_{ 1 3 } }= -0.002481 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 2 }_{ 1 4 } }= -0.002481 \\quad\\frac{\\partial J}{\\partial \\Theta^{ 2 }_{ 1 5 } }= -0.002481 \\quad$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l, (nw, nb) in enumerate(zip(nabla_w, nabla_b)):\n",
    "    for i in range(nw.shape[0]):\n",
    "        text = '$$\\\\frac{{\\\\partial J}}{{\\\\partial \\\\Theta^{}_{{{}0}} }} = {:.5} \\\\quad'.format(\n",
    "            l+1, i+1, nb[i][0])\n",
    "        for j in range(nw.shape[1]):\n",
    "            text += '\\\\frac{{\\partial J}}{{\\\\partial \\\\Theta^{{ {} }}_{{ {} {} }} }}= {:.5} \\\\quad'.format(\n",
    "                l+1, i+1, j+1, nw[i][j])\n",
    "        display(Markdown(text+'$$'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
